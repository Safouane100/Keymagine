{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy, os, random, re, requests, json\n",
    "from pprint import pprint\n",
    "from dspy import Example\n",
    "import tqdm as notebook_tqdm\n",
    "from pprint import pprint\n",
    "from typing import Union, Literal, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "\n",
    "together_openai = dspy.OpenAI(\n",
    "    api_base = os.getenv(\"TOGETHER_API_BASE\"),\n",
    "    api_key= os.getenv(\"TOGETHER_API_KEY\"),\n",
    "    # api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    # model=\"gpt-3.5-turbo-0125\"\n",
    "    # model=\"Qwen/Qwen1.5-72B-Chat\",\n",
    "    # model=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    # model=\"mistralai/Mixtral-8x22B\",\n",
    "    # model=\"mistralai/Mixtral-8x22B-Instruct-v0.1\",\n",
    "    # model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "    # model=\"meta-llama/Meta-Llama-3-70B\",\n",
    "    # model=\"nonexistent/snowflake-arctic-instruct\",\n",
    ")\n",
    "dspy.configure(lm=together_openai, trace=[])\n",
    "# together_openai(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE MONITORING\n",
    "import phoenix as px\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={})\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "DSPyInstrumentor().instrument()\n",
    "\n",
    "phoenix_session = px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, COPRO, MIPRO\n",
    "from llm_modules.candidates import CompiledCandidates\n",
    "# from dspy.functional import TypedPredictor\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "userprefs = [\n",
    "    dict(n=1, foreign_word='Sperre', keywordcount=Counter({'spear': 8, 'pear': 1, 'spare': 1, 'sphere': 1})),\n",
    "    dict(n=2, foreign_word='Hose', keywordcount=Counter({'hose': 7, 'house': 2, 'horse': 1, 'hoes': 1})),\n",
    "    dict(n=3, foreign_word='Nehmen', keywordcount=Counter({'nemo': 5, 'naming': 1, 'neanderthal': 1, 'neiman': 1, 'neem': 1, 'no men': 1, 'nah man': 1})),\n",
    "    dict(n=4, foreign_word='Haben', keywordcount=Counter({'haven': 6, 'have': 2, 'hobby': 1, 'habit': 1, 'happen': 1})),\n",
    "    dict(n=5, foreign_word='Ecke', keywordcount=Counter({'echo': 9, 'eek': 1})),\n",
    "    dict(n=6, foreign_word='Dohle', keywordcount=Counter({'dollar': 2, 'dolly': 1, 'dole': 1, 'doily': 1, 'dolphin': 1, 'ice cream': 1, 'doha': 1, 'dodo': 1, 'owl': 1, 'doll': 1})),\n",
    "    dict(n=7, foreign_word='Kaufen', keywordcount=Counter({'coffin': 7, 'kaufland': 1, 'cough': 1})),\n",
    "    dict(n=8, foreign_word='Fliegen', keywordcount=Counter({'flies': 4, 'fly': 3, 'flying': 2, 'fleeing': 1, 'ÿ∑Ÿäÿßÿ±ÿ©': 1})),\n",
    "    dict(n=9, foreign_word='Leiter', keywordcount=Counter({'leader': 3, 'ladder': 2, 'later': 1, 'lighter': 1, 'latter': 1, 'liter': 1})),\n",
    "    dict(n=10, foreign_word='Friseur', keywordcount=Counter({'freezer': 9, 'fries': 1, 'frisbee': 1})),\n",
    "    dict(n=11, foreign_word='Stellen', keywordcount=Counter({'stallion': 6, 'steal': 1, 'stellan': 1, 'stellar': 1, 'stealing': 1})),\n",
    "    dict(n=12, foreign_word='Brauchen', keywordcount=Counter({'broken': 4, 'bra': 2, 'brunch': 1, 'bracken': 1, 'braunschweig': 1, 'brought': 1, 'break in': 1})),\n",
    "    dict(n=13, foreign_word='Teller', keywordcount=Counter({'teller': 9, 'telly': 1, 'to tell': 1})),\n",
    "    dict(n=14, foreign_word='K√ºche', keywordcount=Counter({'kitchen': 5, 'couch': 2, 'cutie': 1, 'cooking': 1, 'ketchup': 1, 'cook': 1})),\n",
    "    dict(n=15, foreign_word='Mieten', keywordcount=Counter({'mitten': 9, 'meet': 1, 'meeting': 1})),\n",
    "    dict(n=16, foreign_word='Zahlen', keywordcount=Counter({'salad': 2, 'zara': 1, 'betalen': 1, 'zaal': 1, 'sailing': 1, 'zach': 1, 'hall': 1, 'salem': 1, \"sellin'\": 1})),\n",
    "    dict(n=17, foreign_word='Klippe', keywordcount=Counter({'clip': 7, 'clipper': 2})),\n",
    "    dict(n=18, foreign_word='Fahne', keywordcount=Counter({'fan': 8, 'fane': 2})),\n",
    "    dict(n=19, foreign_word='Rufen', keywordcount=Counter({'roofing': 9, 'rufus': 1})),\n",
    "    dict(n=20, foreign_word='Graben', keywordcount=Counter({'grab': 11})),\n",
    "    dict(n=21, foreign_word='Schere', keywordcount=Counter({'chair': 4, 'shears': 2, 'sphere': 2, 'shear': 1, 'cheer': 1, 'sheer': 1})),\n",
    "    dict(n=22, foreign_word='Rasen', keywordcount=Counter({'racing': 4, 'raisin': 3, 'razor': 2, 'rasin': 1, 'raising': 1})),\n",
    "    dict(n=23, foreign_word='Sto√üen', keywordcount=Counter({'stone': 4, 'stolen': 3, 'stopping': 1, 'stowing': 1})),\n",
    "    dict(n=24, foreign_word='Streichen', keywordcount=Counter({'strike': 4, 'stretch': 4, 'striking': 1, 'stricken': 1})),\n",
    "    dict(n=25, foreign_word='Schalter', keywordcount=Counter({'shoulder': 4, 'shelter': 3, 'shatter': 2, 'shall tear': 1, 'saltier': 1})),\n",
    "    dict(n=26, foreign_word='Flasche', keywordcount=Counter({'flash': 7, 'flask': 2, 'flash card': 1})),\n",
    "    dict(n=27, foreign_word='Streiten', keywordcount=Counter({'straighten': 3, 'straiten': 3, 'street': 2, 'stripes': 1, 'straight': 1, 'strengthen': 1})),\n",
    "    dict(n=28, foreign_word='Laufen', keywordcount=Counter({'laughing': 7, 'laugh': 2, 'launch': 1})),\n",
    "    dict(n=29, foreign_word='Br√ºcke', keywordcount=Counter({'bridge': 3, 'brooke': 1, 'broke': 1, 'broken': 1, 'brick': 1, 'brook': 1, 'bruck': 1})),\n",
    "    dict(n=30, foreign_word='Messer', keywordcount=Counter({'mess': 4, 'messi': 2, 'massage': 2, 'massive': 1, 'massacre': 1, 'messier': 1})),\n",
    "    dict(n=31, foreign_word='Treten', keywordcount=Counter({'treat': 9, 'tread': 1, 'treating': 1})),\n",
    "    dict(n=32, foreign_word='Tragen', keywordcount=Counter({'dragon': 3, 'tragic': 2, 'take': 1, 'trigger': 1, 'dragging': 1, 'tragedy': 1})),\n",
    "    dict(n=33, foreign_word='Nagel', keywordcount=Counter({'nail': 5, 'nigel': 2, 'knob': 1, 'navel': 1, 'nagael': 1})),\n",
    "    dict(n=34, foreign_word='Birne', keywordcount=Counter({'burn': 6, 'bear': 1, 'bernie sanders': 1, 'beer': 1, 'berney sanders': 1})),\n",
    "    dict(n=35, foreign_word='Sagen', keywordcount=Counter({'sage': 3, 'saying': 2, 'saigon': 1, 'sagan': 1, 'sagging': 1, 'sacking': 1})),\n",
    "    dict(n=36, foreign_word='Rei√üen', keywordcount=Counter({'rice': 5, 'raisin': 1, 'rise': 1, 'rising': 1, 'rain': 1, 'reisen': 1})),\n",
    "]\n",
    "examples = [Example(language=\"German\", foreign_word=up['foreign_word'], similar_word=k, ratio=v/sum((i for i in up['keywordcount'].values()))).with_inputs(\"language\", \"foreign_word\")\n",
    "            for up in userprefs \n",
    "            for k, v in up['keywordcount'].items()\n",
    "            ]\n",
    "print(len(examples))\n",
    "# examples = [Example(language=\"German\", foreign_word=up['foreign_word'], similar_words = list(up['keywordcount'])).with_inputs(\"language\", \"foreign_word\") for up in userprefs]\n",
    "\n",
    "dl = DataLoader()\n",
    "splits = dl.train_test_split(examples, train_size=0.8) # `dataset` is a List of dspy.Example\n",
    "trainset = splits['train']\n",
    "testset = splits['test']\n",
    "\n",
    "class SimilarOrthography(dspy.Signature):\n",
    "    \"\"\"Generate an English word that is as similar as possible to the foreign word, either orthographically or phonetically.\"\"\"\n",
    "    language = dspy.InputField()\n",
    "    foreign_word = dspy.InputField()\n",
    "    similar_word: list[str] = dspy.OutputField()\n",
    "\n",
    "class SimilarWordModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_word = dspy.Predict(SimilarOrthography)\n",
    "\n",
    "    def forward(self, language, foreign_word, translation=None):\n",
    "        sim_word = self.generate_word(language=language, foreign_word=foreign_word, config=dict(n=10, stop=\"\\n\"))\n",
    "        return sim_word\n",
    "\n",
    "def get_keywordcount(foreign_word):\n",
    "    for pref in userprefs:\n",
    "        if pref['foreign_word'] == foreign_word:\n",
    "            return pref['keywordcount']\n",
    "    return None\n",
    "\n",
    "def weighted_precision(example, prediction, trace=[]):\n",
    "    # print(example)\n",
    "    # print(prediction)\n",
    "    foreign_word = example.foreign_word\n",
    "    candidates = prediction.completions.similar_word\n",
    "    candidates = [p.lower() for p in candidates]\n",
    "\n",
    "    keywordcount = get_keywordcount(foreign_word)\n",
    "    total_weight = sum(keywordcount.values())\n",
    "    match_weight = sum(keywordcount.get(kw, 0) for kw in candidates)\n",
    "    # print(\"--------------------\")\n",
    "    # print(\"foreign_word:\", foreign_word, \"keywordcount:\", keywordcount, \"candidates:\", candidates, \"\\n\", \n",
    "    #       \"match_weight:\", match_weight, \"total_weight:\", total_weight, \"precision:\", match_weight / total_weight if total_weight > 0 else 0)\n",
    "\n",
    "    return match_weight / total_weight if total_weight > 0 else 0\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "def ndcg_score(example, prediction, trace=[]):\n",
    "    candidates = prediction.completions.similar_word\n",
    "    candidates_lower = [p.lower() for p in candidates]\n",
    "    # Remove duplicates, sort by count\n",
    "    candidates_dedup_sorted = sorted(list({p for p in candidates_lower}), key=lambda x: candidates_lower.count(x), reverse=True)\n",
    "    \n",
    "    keywordcount = get_keywordcount(example.foreign_word)\n",
    "    scores = [candidates.count(kw) for kw in candidates_dedup_sorted]\n",
    "    true_relevance = [keywordcount.get(kw, 0) for kw in candidates_dedup_sorted]\n",
    "    if len(scores) < 2:\n",
    "        return 0\n",
    "\n",
    "    return ndcg_score(true_relevance, scores)\n",
    "\n",
    "\n",
    "# smw = SimilarWordModule()\n",
    "# smw(\"German\", \"Hause\").completions\n",
    "# config = dict(max_bootstrapped_demos=4, max_labeled_demos=4, num_candidate_programs=10, num_threads=2)\n",
    "# teleprompter = BootstrapFewShotWithRandomSearch(metric=weighted_precision, **config)\n",
    "# bfswrs_new_examples = teleprompter.compile(SimilarWordModule(), trainset=trainset)\n",
    "\n",
    "# # COPRO\n",
    "# eval_kwargs = dict(num_threads=16, display_progress=True, display_table=0)\n",
    "# copro_teleprompter = COPRO(prompt_model=together_openai, metric=weighted_precision, breadth=5, depth=5, init_temperature=0.7, verbose=True)\n",
    "# compiled_copro = copro_teleprompter.compile(SimilarWordModule(), trainset=trainset, eval_kwargs=eval_kwargs)\n",
    "\n",
    "# MIPRO\n",
    "# teleprompter = MIPRO(prompt_model=together_openai, task_model=model_that_solves_task, metric=your_defined_metric, num_candidates=num_new_prompts_generated, init_temperature=prompt_generation_temperature)\n",
    "# kwargs = dict(num_threads=NUM_THREADS, display_progress=True, display_table=0)\n",
    "# compiled_program_optimized_bayesian_signature = teleprompter.compile(your_dspy_program, trainset=trainset, num_trials=100, max_bootstrapped_demos=3, max_labeled_demos=5, eval_kwargs=kwargs)\n",
    "\n",
    "# BootstrapFewShotWithOptuna\n",
    "# from dspy.teleprompt import BootstrapFewShotWithOptuna\n",
    "# fewshot_optuna_optimizer2 = BootstrapFewShotWithOptuna(metric=weighted_precision, max_bootstrapped_demos=20, num_candidate_programs=8, num_threads=4)\n",
    "# compiled_optuna = fewshot_optuna_optimizer2.compile(student=SimilarWordModule(), max_demos=20, trainset=trainset, valset=trainset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cairo\n"
     ]
    }
   ],
   "source": [
    "# together_openai = dspy.OpenAI(\n",
    "#     api_base = os.getenv(\"TOGETHER_API_BASE\"),\n",
    "#     api_key= os.getenv(\"TOGETHER_API_KEY\"),\n",
    "#     model=\"meta-llama/Meta-Llama-3-70B\",\n",
    "# )\n",
    "# dspy.configure(lm=together_openai, trace=[])\n",
    "\n",
    "pr = dspy.Predict('question -> answer')\n",
    "response = pr(question=\"What is the capital of Egypt?\", config={\"stop\": \"\\n\"})\n",
    "print(response.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(str(optimized_program) + \"sss\")\n",
    "# optimized_program.save(path=\"optimized_fswrs.json\")\n",
    "# optimized_program_2.save(path=\"optimized_fswrs_2.json\")\n",
    "# compiled_copro.save(path=\"compiled_copro.json\")\n",
    "# copmiled_optuna.save(path=\"compiled_optuna.json\")\n",
    "compiled_optuna.save(path=\"compiled_optuna2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabeledFewShot evaluation 136.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.09696969696969 / 34  (91.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [00:01<00:00, 22.24it/s] \n",
      "c:\\Users\\username\\Documents\\School MSc\\Thesis\\llm-vocab\\.venv\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.09696969696969 / 34  (91.5%)\n",
      "LabeledManyShot evaluation 91.46\n",
      "Fewshotwithrandomsearch evaluation 136.47\n",
      "Fewshotwithrandomsearch evaluation 2 141.19\n",
      "Copro evaluation 108.16\n",
      "Optuna evaluation 85.74\n",
      "Optuna evaluation 2 115.77\n",
      "Normal evaluation 108.16\n"
     ]
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "from dspy.teleprompt import LabeledFewShot\n",
    "from pprint import pprint\n",
    "\n",
    "# evaluation = Evaluate(devset=testset, metric=weighted_precision, num_threads=1, display_progress=True, display_table=0)\n",
    "\n",
    "# lfs4 = LabeledFewShot(k=4)\n",
    "# lfs4_optimized = lfs4.compile(SimilarWordModule(), trainset=trainset[:4])\n",
    "# lfs4_evaluation = evaluation(lfs4_optimized)\n",
    "print(\"LabeledFewShot evaluation\", lfs4_evaluation)\n",
    "\n",
    "lms_evaluation = evaluation(LabeledFewShot(k=40).compile(SimilarWordModule(), trainset=trainset))\n",
    "print(\"LabeledManyShot evaluation\", lms_evaluation)\n",
    "\n",
    "# fswrs_optimized = SimilarWordModule()\n",
    "# fswrs_optimized.load(path=\"optimized_fswrs.json\")\n",
    "# fswrs_evaluation = evaluation(fswrs_optimized)\n",
    "print(\"Fewshotwithrandomsearch evaluation\", fswrs_evaluation)\n",
    "\n",
    "# fswrs_optimized_2 = SimilarWordModule()\n",
    "# fswrs_optimized_2.load(path=\"optimized_fswrs_2.json\")\n",
    "# fswrs_evaluation_2 = evaluation(fswrs_optimized_2)\n",
    "print(\"Fewshotwithrandomsearch evaluation 2\", fswrs_evaluation_2)\n",
    "\n",
    "# compiled_copro = SimilarWordModule()\n",
    "# compiled_copro.load(path=\"compiled_copro.json\")\n",
    "# copro_evaluation = evaluation(compiled_copro)\n",
    "print(\"Copro evaluation\", copro_evaluation)\n",
    "\n",
    "# compiled_optuna = SimilarWordModule()\n",
    "# compiled_optuna.load(path=\"compiled_optuna.json\")\n",
    "# optuna_evaluation = evaluation(compiled_optuna)\n",
    "print(\"Optuna evaluation\", optuna_evaluation)\n",
    "\n",
    "# compiled_optuna2 = SimilarWordModule()\n",
    "# compiled_optuna2.load(path=\"compiled_optuna2.json\")\n",
    "# optuna_evaluation_2 = evaluation(compiled_optuna2)\n",
    "print(\"Optuna evaluation 2\", optuna_evaluation_2)\n",
    "\n",
    "# normal_evaluation = evaluation(SimilarWordModule(), display_table=10)\n",
    "print(\"Normal evaluation\", normal_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
